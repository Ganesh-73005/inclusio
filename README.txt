HACK4CHANGE

Team name: Code4good
Team leader: Dharani Raj
Problem Statement: Inclusion
"NOTE: CURRENTLY WE MADE THIS PROTOTYPE FOR TAMIL NADU LOCALITIES ONLY IF YOU ACCESSING THIS FROM ANY OTHER STATES YOU CANT VIEW LOCAL NEWS"
PROTOTYPE BRIEF:

•	Our prototype acts as an efficient solution to the significant challenges faced by marginalized communities due to language and literacy barriers. We have developed a comprehensive platform, accessible via a website, designed to deliver personalized information and news in users' native languages.

•	Our prototype’s main aim is to make sure that no information goes unnoticed because of language barriers. Everyone will be able to access and view information, whether it’s a news article, a document, or a video which is not in their native language, which will be translated into their native language or the language of their choice through the help of our prototype.

•	In addition, the website will include a sophisticated question-answering model that responds to user inquiries from a given document in their native language, enhancing their ability to obtain accurate information. Users will also have the ability to upload documents such as government schemes and medical pamphlets, which will be used to train our Retrieval-Augmented Generation (RAG) model.

•	This model will then be able to answer questions based on the content of these documents, further improving accessibility to critical information. By integrating these features, our solution aims to bridge the information gap, empower users with essential knowledge, and promote greater inclusivity for marginalized communities.



OUR PROTOTYPES’ FEATURES:

1.Location-based personalized news system:
Our prototype detects the location of the user, with their permission and provides the news articles surrounding their locality or city through web scraping. The user can further select the language of their choice and the news will be displayed in their selected language.

2.Audio Translation from a video:
The user will be able to upload video of their choice, and select the language in which they want it to be translated. The original audio will be extracted, transcribed, translated, and the translated audio will be downloaded to the user’s system.


3. Document-Based QA:
We allow users to upload documents like government schemes and medical pamphlets to ensure that critical information can be personalized and easily accessible. The RAG model can then be trained to provide accurate answers based on these documents, enhancing the user's understanding of complex materials. The answers can also be translated to the user’s choice of language.
